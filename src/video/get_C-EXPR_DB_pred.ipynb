{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c111fc-8c36-422c-97c6-04ec603fabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e88a27e-ab69-46be-ac26-8b1e77ca0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate MF1 metric (Macro F1 Score).\n",
    "    \n",
    "    :param y_true: True labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: MF1 (F1 score averaged across all classes)\n",
    "    \"\"\"\n",
    "    return f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "def get_video_info(input_path):\n",
    "    \"\"\"Gets video file duration in seconds and FPS using ffprobe.\"\"\"\n",
    "    # Command to get duration\n",
    "    duration_cmd = f'ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 \"{input_path}\"'\n",
    "    # Command to get FPS\n",
    "    fps_cmd = f'ffprobe -v error -select_streams v -of default=noprint_wrappers=1:nokey=1 -show_entries stream=r_frame_rate \"{input_path}\"'\n",
    "    \n",
    "    try:\n",
    "        duration = float(subprocess.check_output(duration_cmd, shell=True).decode('utf-8').strip())\n",
    "        \n",
    "        # Get FPS (might be in format \"30/1\", so needs calculation)\n",
    "        fps_output = subprocess.check_output(fps_cmd, shell=True).decode('utf-8').strip()\n",
    "        if '/' in fps_output:\n",
    "            numerator, denominator = map(float, fps_output.split('/'))\n",
    "            fps = numerator / denominator\n",
    "        else:\n",
    "            fps = float(fps_output)\n",
    "            \n",
    "        return {'duration': duration, 'fps': fps}\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"Error getting file info for {input_path}\")\n",
    "        return {'duration': 0.0, 'fps': 0.0}\n",
    "\n",
    "def segment_multimodal_file(input_path):\n",
    "    \"\"\"\n",
    "    Segments a multimodal file into 4-second parts with 2-second step.\n",
    "    If file is shorter than 4 seconds - simply copies it with ___0000 index.\n",
    "    \"\"\"\n",
    "    # Check file duration\n",
    "    video_info = get_video_info(input_path)\n",
    "    duration = video_info['duration']\n",
    "    fps = video_info['fps']\n",
    "    \n",
    "    # Get base filename and extension\n",
    "    base_name, ext = os.path.splitext(os.path.basename(input_path))\n",
    "\n",
    "    metadata = []\n",
    "\n",
    "    # Generate segment timings\n",
    "    timings = slice_audio(start_time=0, end_time=duration,\n",
    "                win_max_length=4, win_shift=2, win_min_length=1)\n",
    "\n",
    "    for segment_index, timing in enumerate(timings):\n",
    "        # Convert timing to frame numbers\n",
    "        start_time = timing['start'] * fps\n",
    "        end_time = timing['end'] * fps\n",
    "\n",
    "        # Generate new filename with index\n",
    "        new_name = f\"{base_name}___{segment_index:04d}{ext}\"\n",
    "\n",
    "        # Store segment metadata\n",
    "        metadata.append([new_name, int(float(start_time)), int(float(end_time)), fps])\n",
    "        \n",
    "    return metadata\n",
    "\n",
    "def slice_audio(start_time: float, end_time: float, \n",
    "                win_max_length: float, win_shift: float, win_min_length: float) -> list[dict]:\n",
    "    \"\"\"Slices audio on windows\n",
    "\n",
    "    Args:\n",
    "        start_time (float): Start time of audio\n",
    "        end_time (float): End time of audio\n",
    "        win_max_length (float): Window max length\n",
    "        win_shift (float): Window shift\n",
    "        win_min_length (float): Window min length\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: List of dict with timings, f.e.: {'start': 0, 'end': 12}\n",
    "    \"\"\"    \n",
    "\n",
    "    if end_time < start_time:\n",
    "        return []\n",
    "    elif (end_time - start_time) > win_max_length:\n",
    "        timings = []\n",
    "        while start_time < end_time:\n",
    "            end_time_chunk = start_time + win_max_length\n",
    "            if end_time_chunk < end_time:\n",
    "                timings.append({'start': start_time, 'end': end_time_chunk})\n",
    "            elif end_time_chunk == end_time: # if tail exact `win_max_length` seconds\n",
    "                timings.append({'start': start_time, 'end': end_time_chunk})\n",
    "                break\n",
    "            else: # if tail less then `win_max_length` seconds\n",
    "                if end_time - start_time < win_min_length: # if tail less then `win_min_length` seconds\n",
    "                    break\n",
    "                \n",
    "                timings.append({'start': start_time, 'end': end_time})\n",
    "                break\n",
    "\n",
    "            start_time += win_shift\n",
    "        return timings\n",
    "    else:\n",
    "        return [{'start': start_time, 'end': end_time}]\n",
    "\n",
    "\n",
    "def save_txt(column_names, file_names, labels, save_name):\n",
    "    data_lines = [','.join(column_names)]\n",
    "    for file_name, label in zip(file_names, labels):\n",
    "        data_lines.append(f\"{file_name},{label}\")\n",
    "\n",
    "    with open(save_name, \"w\") as file:\n",
    "        for line in data_lines:\n",
    "            file.write(line + \"\\n\")\n",
    "\n",
    "def get_df(pred, video_names, save_results):\n",
    "    # Extract core video names by removing segment indices and keeping extensions\n",
    "    core_video_names = sorted(set([i.split('___')[0]+i[-4:] for i in video_names]))\n",
    "    compound_emotions = [\"Fearfully_Surprised\",\"Happily_Surprised\",\"Sadly_Surprised\",\n",
    "                        \"Disgustedly_Surprised\",\"Angrily_Surprised\",\"Sadly_Fearful\",\"Sadly_Angry\"]\n",
    "    data = []\n",
    "    \n",
    "    # Process each video file\n",
    "    for idx, video_name in enumerate(tqdm(core_video_names)):\n",
    "        # Get segment metadata for current video\n",
    "        curr_metadata = segment_multimodal_file(f'E:/Databases/9th_ABAW/C-EXPR-DB/videos/{video_name}')\n",
    "        \n",
    "        # Process each segment of the video\n",
    "        for curr_name, start_frame, end_frame, fps in curr_metadata:\n",
    "            # Find index of current segment in video_names list\n",
    "            ind_name = video_names.index(curr_name)\n",
    "            predictions = pred[ind_name]  # Get predictions for this segment\n",
    "            \n",
    "            # Extract base filename (without ___0000.mp4 suffix)\n",
    "            base_name = curr_name.split('___')[0]\n",
    "            \n",
    "            # Generate frame entries for this segment\n",
    "            for frame_num in range(start_frame + 1, end_frame + 1 + 1):  # +1 because of 0-based indexing\n",
    "                frame_name = f\"{frame_num:05d}.jpg\"  # Format as 00001.jpg\n",
    "                \n",
    "                # Add record to data list\n",
    "                data.append({\n",
    "                    'file_name': base_name,\n",
    "                    'segment': curr_name,\n",
    "                    'frame': frame_name,\n",
    "                    compound_emotions[0]: predictions[0],\n",
    "                    compound_emotions[1]: predictions[1],\n",
    "                    compound_emotions[2]: predictions[2],\n",
    "                    compound_emotions[3]: predictions[3],\n",
    "                    compound_emotions[4]: predictions[4],\n",
    "                    compound_emotions[5]: predictions[5],\n",
    "                    compound_emotions[6]: predictions[6]\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame from collected data\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    grouped_df = df.groupby(['file_name', 'frame']).agg({\n",
    "        compound_emotions[0]: 'mean',\n",
    "        compound_emotions[1]: 'mean',\n",
    "        compound_emotions[2]: 'mean',\n",
    "        compound_emotions[3]: 'mean',\n",
    "        compound_emotions[4]: 'mean',\n",
    "        compound_emotions[5]: 'mean',\n",
    "        compound_emotions[6]: 'mean'\n",
    "    }).reset_index()\n",
    "    final_df = grouped_df.copy()\n",
    "    \n",
    "    final_df['image_location'] = [f'{x}/{y}' for x, y in zip(final_df.file_name, final_df.frame)]\n",
    "    final_df[compound_emotions[0]] = np.argmax(final_df[compound_emotions].values, axis=1).tolist()\n",
    "    final_df[compound_emotions[1:]] = None\n",
    "    final_df = final_df[['image_location'] + compound_emotions]\n",
    "    \n",
    "    df = pd.read_csv('ICCV_9th_ABAW_CE_test_set_example.txt')\n",
    "    df_image_location = df[['image_location']]\n",
    "    result = df_image_location.merge(final_df, on='image_location', how='left')\n",
    "    result = result.ffill()\n",
    "    result = result.astype({'Fearfully_Surprised': 'int'})\n",
    "    column_names = ['image_location'] + compound_emotions\n",
    "    save_txt(column_names, result.image_location.tolist(), result.Fearfully_Surprised.tolist(), f'{save_results}.txt')\n",
    "    return result\n",
    "\n",
    "def get_emo_df(feature_path, model1, model2, name_1, name_2):\n",
    "    features_full = []\n",
    "    file = open(feature_path,'rb')\n",
    "    object_file = pickle.load(file)\n",
    "    \n",
    "    for data in tqdm(object_file):\n",
    "        with torch.no_grad():\n",
    "            outputs1 = model1(torch.unsqueeze(data['video'], 0).to('cuda'))\n",
    "            outputs2 = model2(torch.unsqueeze(data['video'], 0).to('cuda'), features=False)\n",
    "        video_name = os.path.basename(data['audio_path'])\n",
    "        outputs1 = torch.softmax(outputs1[0], dim=0).cpu().numpy().tolist()\n",
    "        outputs2 = torch.softmax(outputs2[0], dim=0).cpu().numpy().tolist()\n",
    "        features_full.append([video_name] + outputs1 +outputs2)\n",
    "    \n",
    "    df_res = pd.DataFrame(features_full, columns=[\"video_name\"]+ [f'{name_1}_{i}' for i in emotion]+[f'{name_2}_{i}' for i in emotion])\n",
    "    return df_res\n",
    "    \n",
    "def get_compound_prob(curr_prob):\n",
    "    pairs = [[3, 6], [4, 6], [5, 6], [2, 6], [1, 6], [5, 3], [5, 1]]\n",
    "    curr_compound_prob = []\n",
    "    for pair in pairs:\n",
    "        curr_compound_prob.append(curr_prob[:, pair[0]]+curr_prob[:, pair[1]])\n",
    "    curr_compound_prob = np.array(curr_compound_prob).T\n",
    "    return curr_compound_prob\n",
    "\n",
    "def get_df_compound_pred(pickle_path = '', df_annotation = None, flag_get_compound_prob = True, save_df_name='', modality='audio'):\n",
    "\n",
    "    emotion_names = [\"Neutral\",\"Anger\",\"Disgust\",\"Fear\",\"Happiness\",\"Sadness\",\"Surprise\",\"Other\"]\n",
    "    compound_names = [\"Fearfully_Surprised\",\"Happily_Surprised\",\"Sadly_Surprised\",\"Disgustedly_Surprised\",\"Angrily_Surprised\",\"Sadly_Fearful\",\"Sadly_Angry\"]\n",
    "    df_annotation = df_annotation[['video_name']]\n",
    "    file = open(pickle_path, 'rb')\n",
    "    object_file = pickle.load(file)\n",
    "    features_full = []\n",
    "    \n",
    "    if modality == 'multimodal_feature_fusion':\n",
    "        for data in tqdm(object_file):\n",
    "            video_name = data['metas']['file_name'] + '.mp4'\n",
    "            outputs1 = data['predictions']['emo']\n",
    "            features_full.append([video_name] + outputs1)\n",
    "    elif modality == 'audio':\n",
    "        for data in tqdm(object_file):\n",
    "            video_name = data['metas']['audio_name'][:-4] + '.mp4'\n",
    "            outputs1 = data['predictions']['emo']\n",
    "            features_full.append([video_name] + outputs1)\n",
    "    elif modality == 'scene':\n",
    "        for data in tqdm(object_file):\n",
    "            video_name = data['video_name']\n",
    "            outputs1 = data['probs']\n",
    "            features_full.append([video_name] + outputs1)\n",
    "    \n",
    "    if flag_get_compound_prob:\n",
    "        df_res = pd.DataFrame(features_full, columns=[\"video_name\"]+ emotion)\n",
    "        result = df_annotation.merge(df_res, on='video_name', how='left')\n",
    "        result = result.ffill()\n",
    "        MM_prob = result[emotion].values\n",
    "        MM_prob = get_compound_prob(MM_prob)\n",
    "    else:\n",
    "        df_res = pd.DataFrame(features_full, columns=[\"video_name\"]+ compound_names)\n",
    "        result = df_annotation.merge(df_res, on='video_name', how='left')\n",
    "        result = result.ffill()\n",
    "        MM_prob = result[compound_names].values\n",
    "        \n",
    "    df_compound_pred = get_df(MM_prob, df_annotation.video_name.tolist(), save_df_name)\n",
    "\n",
    "    return df_compound_pred\n",
    "\n",
    "subset = 'test'\n",
    "corpus = 'c-expr-db'\n",
    "\n",
    "path_annotation = 'E:/Databases/9th_ABAW/'\n",
    "full_path_annotation = f'{path_annotation}{corpus.upper()}/Chunk/{subset}_segment.csv'\n",
    "df_annotation = pd.read_csv(full_path_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2a685b7-312a-43dc-86fd-8c93018599e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 449/449 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [00:05<00:00, 10.13it/s]\n"
     ]
    }
   ],
   "source": [
    "path = 'multimodal_predictions/run_20250702_191542_epoch_20_predictions/run_20250702_191542_epoch_20_predictions_compound.pkl'\n",
    "curr_df = get_df_compound_pred(pickle_path = path, df_annotation = df_annotation, flag_get_compound_prob = False, save_df_name='test1', modality='multimodal_feature_fusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507dec73-b97f-4e81-8be2-460cbeb6e213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
